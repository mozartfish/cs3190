{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "xdata = np.genfromtxt('x.csv', delimiter=',')\n",
    "ydata = np.genfromtxt('y.csv', delimiter=',')\n",
    "xTrain= xdata[0:70]\n",
    "xTest = xdata[70:100]\n",
    "yTrain = ydata[0:70]\n",
    "yTest = ydata[70:100]\n",
    "# print(xdata)\n",
    "# print(xTrain)\n",
    "# print(yTrain)\n",
    "# print(xTest)\n",
    "# print(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model using the full data set is y = 6.264767049164256 x + 1.662944116016651\n",
      "y value for 0.4 is 4.168850935682354\n",
      "y value for 0.7 is 6.04828105043163\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART A\n",
    "# find the equation of the line\n",
    "ave_x = np.average(xdata)\n",
    "ave_y = np.average(ydata)\n",
    "# first center the data points\n",
    "xc = xdata - ave_x;\n",
    "yc = ydata - ave_y;\n",
    "\n",
    "# find slope variables a and b\n",
    "a = xc.dot(yc) / xc.dot(xc)\n",
    "b = ave_y - a * ave_x\n",
    "print(\"The model using the full data set is y =\",a,\"x +\", b)\n",
    "\n",
    "# predict y for x value of 0.4\n",
    "y_prime1 = a * 0.4 + b\n",
    "print(\"y value for 0.4 is\", y_prime1)\n",
    "\n",
    "# predict y for x value of 0.7\n",
    "y_prime2 = a * 0.7 + b\n",
    "print(\"y value for 0.7 is\", y_prime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The linear model using the training data set is y = 6.2151326090994985 x + 1.6879716837488536\n",
      "y value for 0.4 is 4.1740247273886535\n",
      "y value for 0.7 is 6.038564510118503\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART B\n",
    "# find the averages\n",
    "ave_xTrain = np.average(xTrain)\n",
    "ave_yTrain = np.average(yTrain)\n",
    "\n",
    "# center the data points\n",
    "xcTrain = xTrain - ave_xTrain\n",
    "ycTrain = yTrain - ave_yTrain\n",
    "\n",
    "aTrain = xcTrain.dot(ycTrain) / xcTrain.dot(xcTrain)\n",
    "bTrain = ave_yTrain - aTrain * ave_xTrain\n",
    "print(\"The linear model using the training data set is y =\",aTrain,\"x +\",bTrain)\n",
    "\n",
    "# predict y for x value of 0.4\n",
    "y_prime1Train = aTrain * 0.4 + bTrain\n",
    "print(\"y value for 0.4 is\", y_prime1Train)\n",
    "\n",
    "# predict y for x value of 0.7\n",
    "y_prime2Train = aTrain * 0.7 + bTrain\n",
    "print(\"y value for 0.7 is\", y_prime2Train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testResidualFullData length is 30\n",
      "testResidualTestData length is 30\n",
      "trainResidualFullData length is 70\n",
      "trainResidualTrainData length is 70\n",
      "Residual vector for the testing data using the model built on the full data [0.45317048493496936, 0.585318654760437, 0.5966626655824561, 0.3241076973768293, 0.7059758354907766, 0.1323197162214944, 0.3222726912565901, 0.04894492349819579, 0.16886174997459413, 0.27712135833349727, 0.0169519943815839, 0.15418348392356584, 0.7222552195931722, 0.3508746498017903, 0.28285948706265973, 0.31291842826956096, 0.08673666692582138, 0.086544073105844, 0.36683823116196823, 0.08619810926227611, 0.04763999440035693, 0.020331259779701405, 0.07956455925186567, 0.22099384179278836, 0.11684475912128356, 0.21614274432548974, 0.26810166356740783, 0.08918782960863147, 0.3902301983186449, 0.23031410144793485]\n",
      "Residual vector for the testing data using the model built on the training data [0.43061471231799153, 0.5785007657470915, 0.5970914048185652, 0.34766112223910883, 0.7291979069455241, 0.13180043765236604, 0.32888588172476796, 0.04229082813706331, 0.16526017267744475, 0.26810962706928976, 0.004560157748965565, 0.14487890946297632, 0.7073133700821281, 0.3726722128266795, 0.300254475253805, 0.31112474193167117, 0.08439580440631733, 0.08542045170882862, 0.38716165131693536, 0.11037196462536492, 0.042599018341330286, 0.022378081761922353, 0.07375048326873035, 0.21283085945368896, 0.11277781542842824, 0.2351905593707908, 0.2726848054369375, 0.06919696020209987, 0.385978409856647, 0.2224848671981703]\n",
      "2 norm for the testing data using the model built on the full data: 1.77303004585815\n",
      "2 norm for the testing data using the model built on the training data: 1.7827144934304198\n",
      "2 norm for the training data using the model built on the full data: 2.567544020806572\n",
      "2 norm for the training data using the model built on the training data: 2.564685068195853\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART C\n",
    "# vectors for storing the values of the residuals\n",
    "testResidualFullData = []\n",
    "testResidualTrainData = []\n",
    "trainResidualFullData = []\n",
    "trainResidualTrainData = []\n",
    "\n",
    "# compute the residual for the testing data using the model built on the full data\n",
    "for i in range(len(xTest)):\n",
    "    testResidualFullData.append(abs(yTest[i] - (a * xTest[i] + b)))\n",
    "# print(residualFullData)\n",
    "\n",
    "# compute the residual for the testing data using the model built on the training data\n",
    "for j in range(len(xTest)):\n",
    "    testResidualTrainData.append(abs(yTest[j] - (aTrain * xTest[j] + bTrain)))\n",
    "\n",
    "# compute the residual for the training data using the model built on the full data\n",
    "for k in range(len(xTrain)):\n",
    "    trainResidualFullData.append(abs(yTrain[k] - (a * xTrain[k] + b)))\n",
    "    \n",
    "# compute the residual for the training datan using the model built on the training data\n",
    "for m in range(len(xTrain)):\n",
    "    trainResidualTrainData.append(abs(yTrain[m] - (aTrain * xTrain[m] + bTrain)))\n",
    "\n",
    "# Vectors for the testing data\n",
    "# print(residualFullData)\n",
    "# print(residualTrainData)\n",
    "\n",
    "# Compute the 2 norms\n",
    "twoNormTestFullData = np.linalg.norm(testResidualFullData, 2)\n",
    "twoNormTestTrainData = np.linalg.norm(testResidualTrainData, 2)\n",
    "twoNormTrainFullData = np.linalg.norm(trainResidualFullData, 2)\n",
    "twoNormTrainTrainData = np.linalg.norm(trainResidualTrainData, 2)\n",
    "\n",
    "# Check the size of all the vectors\n",
    "print(\"testResidualFullData length is\", len(testResidualFullData))\n",
    "print(\"testResidualTestData length is\", len(testResidualTrainData))\n",
    "print(\"trainResidualFullData length is\", len(trainResidualFullData))\n",
    "print(\"trainResidualTrainData length is\", len(trainResidualTrainData))\n",
    "\n",
    "# Report the results\n",
    "print(\"Residual vector for the testing data using the model built on the full data\", testResidualFullData)\n",
    "print(\"Residual vector for the testing data using the model built on the training data\", testResidualTrainData)\n",
    "# print(\"Residual vector for the training data using the model built on the full data\", trainResidualFullData)\n",
    "# print(\"Residual vector for the training data using the model built on the training data\", trainResidualTrainData)\n",
    "print(\"2 norm for the testing data using the model built on the full data:\", twoNormTestFullData)\n",
    "print(\"2 norm for the testing data using the model built on the training data:\", twoNormTestTrainData)\n",
    "print(\"2 norm for the training data using the model built on the full data:\", twoNormTrainFullData)\n",
    "print(\"2 norm for the training data using the model built on the training data:\", twoNormTrainTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.5472, 0.29942784, 0.16384691404800003, 0.08965703136706561]\n",
      "[1.0, 0.4718, 0.22259524, 0.105020434232, 0.0495486408706576]\n",
      "[1.0, 0.7712, 0.59474944, 0.458670768128, 0.35372689638031357]\n",
      "[1.0, 0.4957, 0.24571848999999998, 0.12180265549299998, 0.060377576327880086]\n",
      "[1.0, 0.3838, 0.14730243999999998, 0.05653467647199999, 0.021698008829953593]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART D FULL DATA\n",
    "outerList = []\n",
    "innerList = []\n",
    "printList = []\n",
    "for p in range(5):\n",
    "    for g in range(5):\n",
    "        innerList.append(pow(xdata[p], g))\n",
    "    print(innerList)\n",
    "    innerList = []\n",
    "# print(\"The matrix is\", outerList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for the training data is 2.377340224491974 + -4.6569927439834125 x + 63.671652675281095 x^2 + -162.81370205380654 x^3 + 178.08233610180628 x^4 + -68.35859916382913 x^5\n",
      "the two norm for the train data matrix is 1.5720382928735723\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART D TRAIN DATA\n",
    "matrixP = np.vander(xTrain, 6, True)\n",
    "alphaXList = []\n",
    "trainingDataResidualMatrix = []\n",
    "# print(\"The matrix for the train data\", matrixP)\n",
    "matrixPTranspose = np.transpose(matrixP)\n",
    "alpha = np.linalg.inv(matrixPTranspose.dot(matrixP)).dot(matrixPTranspose).dot(yTrain)\n",
    "print(\"The model for the training data is\", alpha[0], \"+\", alpha[1], \"x\",\"+\",alpha[2],\"x^2\", \"+\", alpha[3],\"x^3\", \"+\",\n",
    "     alpha[4], \"x^4\", \"+\", alpha[5], \"x^5\")\n",
    "# print(\"alpha values\", alpha)\n",
    "for f in range(len(xTrain)):\n",
    "    value1 = pow(xTrain[f], 0) * alpha[0]\n",
    "    value2 = pow(xTrain[f], 1) * alpha[1]\n",
    "    value3 = pow(xTrain[f], 2) * alpha[2]\n",
    "    value4 = pow(xTrain[f], 3) * alpha[3]\n",
    "    value5 = pow(xTrain[f], 4) * alpha[4]\n",
    "    value6 = pow(xTrain[f], 5) * alpha[5]\n",
    "    totalSum = value1 + value2 + value3 + value4 + value5 + value6\n",
    "    alphaXList.append(totalSum)\n",
    "\n",
    "for r in range(len(xTrain)):\n",
    "    trainingDataResidualMatrix.append(abs(alphaXList[r] - yTrain[r]))\n",
    "\n",
    "\n",
    "\n",
    "twoNormTrainData = np.linalg.norm(trainingDataResidualMatrix, 2)\n",
    "print(\"the two norm for the train data matrix is\", twoNormTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for the testing data is 1.1228696344917353 + 27.240740012963375 x + -113.30375247461836 x^2 + 236.66466792344102 x^3 + -221.31374565103113 x^4 + 78.43209032230601 x^5\n",
      "the two norm for the test data matrix is 1.1515091353439482\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART D TEST DATA\n",
    "matrixPTest = np.vander(xTest, 6, True)\n",
    "alphaXTestList = []\n",
    "testingDataResidualMatrix = []\n",
    "# print(\"The matrix for the test data is\", matrixPTest)\n",
    "matrixPTestTranspose = np.transpose(matrixPTest)\n",
    "alphaTest = np.linalg.inv(matrixPTestTranspose.dot(matrixPTest)).dot(matrixPTestTranspose).dot(yTest)\n",
    "print(\"The model for the testing data is\", alphaTest[0], \"+\", alphaTest[1], \"x\",\"+\",alphaTest[2],\"x^2\", \"+\", alphaTest[3],\"x^3\", \"+\",\n",
    "     alphaTest[4], \"x^4\", \"+\", alphaTest[5], \"x^5\")\n",
    "# print(\"alpha values\", alpha)\n",
    "for f in range(len(xTest)):\n",
    "    value1Test = pow(xTest[f], 0) * alphaTest[0]\n",
    "    value2Test = pow(xTest[f], 1) * alphaTest[1]\n",
    "    value3Test = pow(xTest[f], 2) * alphaTest[2]\n",
    "    value4Test = pow(xTest[f], 3) * alphaTest[3]\n",
    "    value5Test = pow(xTest[f], 4) * alphaTest[4]\n",
    "    value6Test = pow(xTest[f], 5) * alphaTest[5]\n",
    "    totalSumTest = value1Test + value2Test + value3Test + value4Test + value5Test + value6Test\n",
    "    alphaXTestList.append(totalSumTest)\n",
    "\n",
    "for r in range(len(xTest)):\n",
    "    testingDataResidualMatrix.append(abs(alphaXTestList[r] - yTest[r]))\n",
    "\n",
    "twoNormTestData = np.linalg.norm(testingDataResidualMatrix, 2)\n",
    "print(\"the two norm for the test data matrix is\", twoNormTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value for current step is [0.04 1.9 ]\n",
      "value for current step is [0.0801 1.8018]\n",
      "value for current step is [0.12029   1.7053635]\n",
      "value for current step is [0.16056028 1.61065478]\n",
      "value for current step is [0.20090141 1.51763888]\n",
      "value for current step is [0.2413042 1.4262816]\n",
      "value for current step is [0.28175975 1.33654945]\n",
      "value for current step is [0.3222594  1.24840966]\n",
      "value for current step is [0.36279476 1.16183017]\n",
      "value for current step is [0.40335766 1.07677959]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 3 PART A using function 1\n",
    "def func(x, y):\n",
    "    return(x - 5) ** 2 + (2 * ((y + 3) ** 2)) + (x * y)\n",
    "\n",
    "def func_grad(vx, vy):\n",
    "    dfdx = 2 * (vx - 5) + vy\n",
    "    dfdy = 4 * (vy + 3) + vx\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "# iteration location\n",
    "v_init = np.array([0, 2])\n",
    "num_iter = 11\n",
    "values = np.zeros([num_iter, 2])\n",
    "\n",
    "for gamma in [0.005]:\n",
    "    values[0,:] = v_init\n",
    "    v = v_init\n",
    "\n",
    "# actual gradient descent algorithm\n",
    "for i in range(1, num_iter):\n",
    "    v = v - gamma * func_grad(v[0], v[1])\n",
    "    values[i,:] = v\n",
    "    print(\"value for current step is\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value for current step is [-0.09   1.826]\n",
      "value for current step is [-0.16595172  1.65418736]\n",
      "value for current step is [-0.22663682  1.49788325]\n",
      "value for current step is [-0.27214707  1.36866618]\n",
      "value for current step is [-0.30414516  1.27216106]\n",
      "value for current step is [-0.32545798  1.20669432]\n",
      "value for current step is [-0.33921588  1.16572999]\n",
      "value for current step is [-0.34810301  1.14163001]\n",
      "value for current step is [-0.35405375  1.12808777]\n",
      "value for current step is [-0.35831048  1.12076707]\n",
      "value for current step is [-0.36161567  1.11698231]\n",
      "value for current step is [-0.36439453  1.11516608]\n",
      "value for current step is [-0.36688473  1.11443336]\n",
      "value for current step is [-0.36921734  1.11429347]\n",
      "value for current step is [-0.37146415  1.11447696]\n",
      "value for current step is [-0.37366431  1.11483662]\n",
      "value for current step is [-0.37583915  1.11529224]\n",
      "value for current step is [-0.37800028  1.11580019]\n",
      "value for current step is [-0.380154   1.1163367]\n",
      "value for current step is [-0.38230376  1.11688885]\n",
      "value for current step is [-0.38445142  1.11744962]\n",
      "value for current step is [-0.386598    1.11801518]\n",
      "value for current step is [-0.38874405  1.11858345]\n",
      "value for current step is [-0.39088988  1.1191533 ]\n",
      "value for current step is [-0.39303566  1.11972409]\n",
      "value for current step is [-0.39518146  1.12029551]\n",
      "value for current step is [-0.39732735  1.12086735]\n",
      "value for current step is [-0.39947334  1.12143954]\n",
      "value for current step is [-0.40161946  1.122012  ]\n",
      "value for current step is [-0.40376571  1.1225847 ]\n",
      "value for current step is [-0.40591209  1.12315765]\n",
      "value for current step is [-0.40805861  1.12373081]\n",
      "value for current step is [-0.41020527  1.1243042 ]\n",
      "value for current step is [-0.41235207  1.1248778 ]\n",
      "value for current step is [-0.41449901  1.12545162]\n",
      "value for current step is [-0.41664609  1.12602565]\n",
      "value for current step is [-0.41879331  1.1265999 ]\n",
      "value for current step is [-0.42094067  1.12717436]\n",
      "value for current step is [-0.42308818  1.12774904]\n",
      "value for current step is [-0.42523582  1.12832393]\n",
      "value for current step is [-0.42738361  1.12889904]\n",
      "value for current step is [-0.42953154  1.12947436]\n",
      "value for current step is [-0.43167961  1.1300499 ]\n",
      "value for current step is [-0.43382782  1.13062566]\n",
      "value for current step is [-0.43597617  1.13120163]\n",
      "value for current step is [-0.43812466  1.13177782]\n",
      "value for current step is [-0.4402733   1.13235423]\n",
      "value for current step is [-0.44242208  1.13293085]\n",
      "value for current step is [-0.444571    1.13350769]\n",
      "value for current step is [-0.44672006  1.13408474]\n",
      "value for current step is [-0.44886927  1.13466202]\n",
      "value for current step is [-0.45101862  1.13523951]\n",
      "value for current step is [-0.45316811  1.13581722]\n",
      "value for current step is [-0.45531774  1.13639515]\n",
      "value for current step is [-0.45746752  1.1369733 ]\n",
      "value for current step is [-0.45961744  1.13755166]\n",
      "value for current step is [-0.4617675   1.13813025]\n",
      "value for current step is [-0.46391771  1.13870905]\n",
      "value for current step is [-0.46606805  1.13928807]\n",
      "value for current step is [-0.46821855  1.13986732]\n",
      "value for current step is [-0.47036918  1.14044678]\n",
      "value for current step is [-0.47251996  1.14102646]\n",
      "value for current step is [-0.47467088  1.14160637]\n",
      "value for current step is [-0.47682195  1.14218649]\n",
      "value for current step is [-0.47897316  1.14276684]\n",
      "value for current step is [-0.48112452  1.1433474 ]\n",
      "value for current step is [-0.48327601  1.14392819]\n",
      "value for current step is [-0.48542766  1.1445092 ]\n",
      "value for current step is [-0.48757944  1.14509043]\n",
      "value for current step is [-0.48973137  1.14567188]\n",
      "value for current step is [-0.49188345  1.14625356]\n",
      "value for current step is [-0.49403567  1.14683546]\n",
      "value for current step is [-0.49618804  1.14741758]\n",
      "value for current step is [-0.49834055  1.14799992]\n",
      "value for current step is [-0.5004932   1.14858249]\n",
      "value for current step is [-0.502646    1.14916528]\n",
      "value for current step is [-0.50479894  1.14974829]\n",
      "value for current step is [-0.50695203  1.15033153]\n",
      "value for current step is [-0.50910527  1.15091499]\n",
      "value for current step is [-0.51125865  1.15149868]\n",
      "value for current step is [-0.51341218  1.15208259]\n",
      "value for current step is [-0.51556585  1.15266673]\n",
      "value for current step is [-0.51771967  1.15325109]\n",
      "value for current step is [-0.51987363  1.15383567]\n",
      "value for current step is [-0.52202774  1.15442049]\n",
      "value for current step is [-0.524182    1.15500553]\n",
      "value for current step is [-0.5263364   1.15559079]\n",
      "value for current step is [-0.52849095  1.15617628]\n",
      "value for current step is [-0.53064564  1.156762  ]\n",
      "value for current step is [-0.53280048  1.15734794]\n",
      "value for current step is [-0.53495547  1.15793412]\n",
      "value for current step is [-0.5371106   1.15852051]\n",
      "value for current step is [-0.53926588  1.15910714]\n",
      "value for current step is [-0.54142131  1.159694  ]\n",
      "value for current step is [-0.54357689  1.16028108]\n",
      "value for current step is [-0.54573261  1.16086839]\n",
      "value for current step is [-0.54788848  1.16145593]\n",
      "value for current step is [-0.55004449  1.1620437 ]\n",
      "value for current step is [-0.55220066  1.1626317 ]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 3 PART A using function 2\n",
    "def func(x, y):\n",
    "    return(1 - (y - 3)) ** 2 + (10 * ((x + 4) - ((y - 3) ** 2)) ** 2)\n",
    "\n",
    "def func_grad(vx, vy):\n",
    "    dfdx = 20 * vx - 20 * (vy - 3) ** 2 + 80\n",
    "    dfdy = 2 * vy - 40 * (vy - 3) * (vx - (vy - 3) ** 2 + 4) - 8\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "# iteration location\n",
    "v_init = np.array([0, 2])\n",
    "num_iter = 100\n",
    "values = np.zeros([num_iter, 2])\n",
    "\n",
    "for gamma in [0.0015]:\n",
    "    values[0,:] = v_init\n",
    "    v = v_init\n",
    "\n",
    "# actual gradient descent algorithm\n",
    "for i in range(1, num_iter):\n",
    "    v = v - gamma * func_grad(v[0], v[1])\n",
    "    values[i,:] = v\n",
    "    print(\"value for current step is\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value for current step is [4.0000e-05 1.9999e+00]\n",
      "value for current step is [8.00001e-05 1.99980e+00]\n",
      "value for current step is [1.20000300e-04 1.99970001e+00]\n",
      "value for current step is [1.60000600e-04 1.99960001e+00]\n",
      "value for current step is [2.00001000e-04 1.99950002e+00]\n",
      "value for current step is [2.40001500e-04 1.99940003e+00]\n",
      "value for current step is [2.80002100e-04 1.99930004e+00]\n",
      "value for current step is [3.20002799e-04 1.99920005e+00]\n",
      "value for current step is [3.60003599e-04 1.99910006e+00]\n",
      "value for current step is [4.00004499e-04 1.99900008e+00]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 3 PART D using function 1\n",
    "def func(x, y):\n",
    "    return(x - 5) ** 2 + (2 * ((y + 3) ** 2)) + (x * y)\n",
    "\n",
    "def func_grad(vx, vy):\n",
    "    dfdx = 2 * (vx - 5) + vy\n",
    "    dfdy = 4 * (vy + 3) + vx\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "# iteration location\n",
    "v_init = np.array([0, 2])\n",
    "num_iter = 11\n",
    "values = np.zeros([num_iter, 2])\n",
    "\n",
    "for gamma in [0.000005]:\n",
    "    values[0,:] = v_init\n",
    "    v = v_init\n",
    "\n",
    "# actual gradient descent algorithm\n",
    "for i in range(1, num_iter):\n",
    "    v = v - gamma * func_grad(v[0], v[1])\n",
    "    values[i,:] = v\n",
    "    print(\"value for current step is\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value for current step is [-0.18   1.652]\n",
      "value for current step is [-0.30017376  1.34209954]\n",
      "value for current step is [-0.3572453   1.16880908]\n",
      "value for current step is [-0.37461497  1.12218186]\n",
      "value for current step is [-0.38056601  1.11709881]\n",
      "value for current step is [-0.38501304  1.1176496 ]\n",
      "value for current step is [-0.38931768  1.11873804]\n",
      "value for current step is [-0.39360982  1.11987631]\n",
      "value for current step is [-0.39790133  1.12101993]\n",
      "value for current step is [-0.40219328  1.12216482]\n",
      "value for current step is [-0.40648579  1.1233106 ]\n",
      "value for current step is [-0.41077885  1.12445723]\n",
      "value for current step is [-0.41507248  1.12560472]\n",
      "value for current step is [-0.41936667  1.12675307]\n",
      "value for current step is [-0.42366143  1.12790227]\n",
      "value for current step is [-0.42795675  1.12905234]\n",
      "value for current step is [-0.43225263  1.13020327]\n",
      "value for current step is [-0.43654909  1.13135506]\n",
      "value for current step is [-0.44084611  1.13250772]\n",
      "value for current step is [-0.4451437   1.13366125]\n",
      "value for current step is [-0.44944185  1.13481564]\n",
      "value for current step is [-0.45374058  1.13597091]\n",
      "value for current step is [-0.45803988  1.13712705]\n",
      "value for current step is [-0.46233975  1.13828407]\n",
      "value for current step is [-0.46664019  1.13944196]\n",
      "value for current step is [-0.47094121  1.14060073]\n",
      "value for current step is [-0.4752428   1.14176038]\n",
      "value for current step is [-0.47954496  1.14292092]\n",
      "value for current step is [-0.4838477   1.14408234]\n",
      "value for current step is [-0.48815101  1.14524464]\n",
      "value for current step is [-0.49245491  1.14640784]\n",
      "value for current step is [-0.49675938  1.14757192]\n",
      "value for current step is [-0.50106443  1.1487369 ]\n",
      "value for current step is [-0.50537006  1.14990277]\n",
      "value for current step is [-0.50967627  1.15106954]\n",
      "value for current step is [-0.51398306  1.1522372 ]\n",
      "value for current step is [-0.51829044  1.15340576]\n",
      "value for current step is [-0.52259839  1.15457523]\n",
      "value for current step is [-0.52690694  1.1557456 ]\n",
      "value for current step is [-0.53121606  1.15691688]\n",
      "value for current step is [-0.53552577  1.15808906]\n",
      "value for current step is [-0.53983607  1.15926215]\n",
      "value for current step is [-0.54414696  1.16043616]\n",
      "value for current step is [-0.54845843  1.16161107]\n",
      "value for current step is [-0.5527705   1.16278691]\n",
      "value for current step is [-0.55708315  1.16396366]\n",
      "value for current step is [-0.56139639  1.16514133]\n",
      "value for current step is [-0.56571023  1.16631992]\n",
      "value for current step is [-0.57002466  1.16749944]\n",
      "value for current step is [-0.57433968  1.16867988]\n",
      "value for current step is [-0.5786553   1.16986125]\n",
      "value for current step is [-0.58297151  1.17104355]\n",
      "value for current step is [-0.58728832  1.17222678]\n",
      "value for current step is [-0.59160572  1.17341095]\n",
      "value for current step is [-0.59592373  1.17459605]\n",
      "value for current step is [-0.60024233  1.17578209]\n",
      "value for current step is [-0.60456153  1.17696907]\n",
      "value for current step is [-0.60888133  1.17815699]\n",
      "value for current step is [-0.61320173  1.17934586]\n",
      "value for current step is [-0.61752274  1.18053567]\n",
      "value for current step is [-0.62184435  1.18172643]\n",
      "value for current step is [-0.62616656  1.18291814]\n",
      "value for current step is [-0.63048938  1.18411081]\n",
      "value for current step is [-0.6348128   1.18530443]\n",
      "value for current step is [-0.63913683  1.186499  ]\n",
      "value for current step is [-0.64346147  1.18769454]\n",
      "value for current step is [-0.64778672  1.18889103]\n",
      "value for current step is [-0.65211257  1.1900885 ]\n",
      "value for current step is [-0.65643904  1.19128692]\n",
      "value for current step is [-0.66076612  1.19248632]\n",
      "value for current step is [-0.66509381  1.19368668]\n",
      "value for current step is [-0.66942211  1.19488802]\n",
      "value for current step is [-0.67375103  1.19609033]\n",
      "value for current step is [-0.67808056  1.19729362]\n",
      "value for current step is [-0.68241071  1.19849788]\n",
      "value for current step is [-0.68674147  1.19970313]\n",
      "value for current step is [-0.69107285  1.20090936]\n",
      "value for current step is [-0.69540486  1.20211658]\n",
      "value for current step is [-0.69973748  1.20332478]\n",
      "value for current step is [-0.70407072  1.20453398]\n",
      "value for current step is [-0.70840458  1.20574417]\n",
      "value for current step is [-0.71273907  1.20695535]\n",
      "value for current step is [-0.71707418  1.20816753]\n",
      "value for current step is [-0.72140991  1.20938071]\n",
      "value for current step is [-0.72574627  1.21059489]\n",
      "value for current step is [-0.73008325  1.21181007]\n",
      "value for current step is [-0.73442087  1.21302626]\n",
      "value for current step is [-0.73875911  1.21424346]\n",
      "value for current step is [-0.74309797  1.21546167]\n",
      "value for current step is [-0.74743747  1.2166809 ]\n",
      "value for current step is [-0.7517776   1.21790114]\n",
      "value for current step is [-0.75611837  1.2191224 ]\n",
      "value for current step is [-0.76045976  1.22034467]\n",
      "value for current step is [-0.76480179  1.22156797]\n",
      "value for current step is [-0.76914446  1.2227923 ]\n",
      "value for current step is [-0.77348776  1.22401765]\n",
      "value for current step is [-0.77783169  1.22524404]\n",
      "value for current step is [-0.78217627  1.22647145]\n",
      "value for current step is [-0.78652148  1.2276999 ]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 3 PART D using function 2\n",
    "def func(x, y):\n",
    "    return(1 - (y - 3)) ** 2 + (10 * ((x + 4) - ((y - 3) ** 2)) ** 2)\n",
    "\n",
    "def func_grad(vx, vy):\n",
    "    dfdx = 20 * vx - 20 * (vy - 3) ** 2 + 80\n",
    "    dfdy = 2 * vy - 40 * (vy - 3) * (vx - (vy - 3) ** 2 + 4) - 8\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "# iteration location\n",
    "v_init = np.array([0, 2])\n",
    "num_iter = 100\n",
    "values = np.zeros([num_iter, 2])\n",
    "\n",
    "for gamma in [0.003]:\n",
    "    values[0,:] = v_init\n",
    "    v = v_init\n",
    "\n",
    "# actual gradient descent algorithm\n",
    "for i in range(1, num_iter):\n",
    "    v = v - gamma * func_grad(v[0], v[1])\n",
    "    values[i,:] = v\n",
    "    print(\"value for current step is\", v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
